# 近期方案 (v0.5.0) - CLI接口与多表支持演进

## 1. 引言

本文档旨在为《近期计划的需求.md》中定义的目标提供具体的技术方案与设计思路。

所有方案都将严格遵循 `notes/Design_Schema_Validation_Command.md` 中阐述的核心架构，即：**CLI层负责解析和分解用户输入，生成原子化的规则对象；Core层负责执行这些原子规则**。本次重构的核心是将变更控制在CLI层，以证明现有架构的健壮性和可扩展性。

---

## 2. `check` 命令接口重构方案 ✅ 已完成

*   **目标**: 将接口从 `vlite-cli check <data_source>` 模式重构为 `vlite-cli check --conn <string> --table <string>` 模式。
*   **影响模块**: `cli/app.py`, `cli/commands/check.py`。
*   **重构策略**: 直接替换旧接口，不保留向后兼容性。
*   **状态**: ✅ 已完成 - 新接口已实现并正常工作

### 2.1. 新接口设计

```python
# 位于 cli/commands/check.py

@click.command("check")
@click.option(
    "--conn",
    "connection_string",
    required=True,
    help="Database connection string or file path"
)
@click.option(
    "--table",
    "table_name", 
    required=True,
    help="Table name to validate"
)
@click.option(
    "--rule",
    "rules",
    multiple=True,
    help="Inline rule expression (can be used multiple times)"
)
@click.option(
    "--rules",
    "rules_file",
    type=click.Path(exists=True, readable=True),
    help="Path to rules file (JSON format)"
)
@click.option("--quiet", is_flag=True, default=False, help="Show summary only")
@click.option(
    "--verbose",
    is_flag=True,
    default=False,
    help="Show detailed information and failure samples"
)
def check_command(
    connection_string: str,
    table_name: str,
    rules: Tuple[str, ...],
    rules_file: Optional[str],
    quiet: bool,
    verbose: bool,
) -> None:
    """
    Check data quality for the given source.
    
    NEW FORMAT:
        vlite-cli check --conn <connection> --table <table_name> [options]
    
    SOURCE can be:
    - File path: users.csv, data.xlsx, records.json
    - Database URL: mysql://user:pass@host/db
    - SQLite file: sqlite:///path/to/file.db

    Examples:
        vlite-cli check --conn users.csv --table users --rule "not_null(id)"
        vlite-cli check --conn mysql://user:pass@host/db --table users --rules validation.json
    """
    # Record start time
    start_time = now()
    logger.info(f"Starting data quality check for: {connection_string}")

    # Create exception handler
    exception_handler = CliExceptionHandler(verbose=verbose)

    # Initialize error variables
    cli_error = None
    schema_error = None
    engine_error = None
    results = None

    try:
        # Phase 1: CLI self-processing and Schema creation
        try:
            # Load configurations using new system
            core_config = get_core_config()
            cli_config = get_cli_config()

            # Initialize components
            source_parser = SourceParser()
            rule_parser = RuleParser()
            output_formatter = OutputFormatter(quiet=quiet, verbose=verbose)

            # Validate inputs
            if not rules and not rules_file:
                raise click.UsageError(
                    "No rules specified. Use --rule for inline rules or "
                    "--rules for rules file."
                )

            # Parse source
            safe_echo(f"🔍 Analyzing source: {connection_string}")

            # Proactively verify that a provided file is not empty
            potential_path = Path(connection_string)
            if potential_path.exists() and potential_path.is_file():
                if potential_path.stat().st_size == 0:
                    raise click.ClickException(
                        f"Error: Source file '{connection_string}' is empty "
                        "– nothing to validate."
                    )

            # Parse source config
            source_config = source_parser.parse_source(connection_string)

            # Parse rules
            safe_echo("📋 Loading validation rules...")
            rule_configs = rule_parser.parse_rules(
                inline_rules=list(rules) if rules else [], rules_file=rules_file
            )

            if not rule_configs:
                raise click.UsageError("No valid rules found.")

            safe_echo(f"   Found {len(rule_configs)} validation rules")

            # Create data validator
            validator = DataValidator(
                source_config=source_config,
                rules=cast(list, rule_configs),
                core_config=core_config,
                cli_config=cli_config,
            )
        except (OperationError, RuleExecutionError) as e:
            schema_error = e
            raise
        except Exception as e:
            cli_error = e
            raise

        # Phase 2: Core validation execution
        try:
            # Execute validation
            safe_echo("✅ Starting validation...")
            results = asyncio.run(validator.validate())
            results_dicts = (
                [r.model_dump() for r in results] if results is not None else []
            )
        except EngineError as e:
            engine_error = e
            raise
        logger.info(f"Results: {results}")

        # Phase 3: Result processing
        error_context = exception_handler.handle_complete_process(
            cli_error=cli_error,
            schema_error=schema_error,
            engine_error=engine_error,
            results=results,
        )

        # Decide output and exit code based on error context
        if error_context.category != "success":
            # Show error message
            safe_echo(f"❌ {error_context.user_message}", err=True)

            # Show recovery suggestions
            if error_context.recovery_actions:
                safe_echo("\nSuggested actions:")
                for action in error_context.recovery_actions:
                    safe_echo(f"• {action}")

            # Show technical details (if verbose enabled)
            if verbose and error_context.technical_details:
                safe_echo(f"\nTechnical details:\n{error_context.technical_details}")

            sys.exit(error_context.exit_code)
        else:
            # On success, calculate execution time and display results
            end_time = now()
            execution_time = (end_time - start_time).total_seconds()

            # Format and display results
            output_formatter.display_results(
                results=results_dicts,
                rules=rule_configs,
                source=connection_string,
                execution_time=execution_time,
                total_rules=len(rule_configs),
            )

            # Set exit code based on validation results
            has_failures = any(result["status"] == "FAILED" for result in results_dicts)

            if has_failures:
                logger.warning("Validation completed with failures")
                sys.exit(1)
            else:
                logger.info("All validations passed successfully")
                safe_echo(f"✅ {error_context.user_message}")
                sys.exit(0)

    except click.UsageError:
        raise

    except Exception as e:
        # Unified error handling
        if isinstance(e, EngineError):
            engine_error = e

        error_context = exception_handler.handle_complete_process(
            cli_error=cli_error,
            schema_error=schema_error,
            engine_error=engine_error,
            results=results,
        )

        if error_context.category == "success":
            # On success, calculate execution time and display results
            end_time = now()
            execution_time = (end_time - start_time).total_seconds()

            # Format and display results
            output_formatter.display_results(
                results=results_dicts,
                rules=rule_configs,
                source=connection_string,
                execution_time=execution_time,
                total_rules=len(rule_configs),
            )

            # Show success message
            safe_echo(f"✅ {error_context.user_message}")
            sys.exit(0)
        else:
            # Show error message
            safe_echo(f"❌ {error_context.user_message}", err=True)

            if error_context.recovery_actions:
                safe_echo("\nSuggested actions:")
                for action in error_context.recovery_actions:
                    safe_echo(f"• {action}")

            if verbose and error_context.technical_details:
                safe_echo(f"\nTechnical details:\n{error_context.technical_details}")

            sys.exit(error_context.exit_code)
```

### 2.2. 接口变更说明

*   **移除位置参数**: 不再支持 `<source>` 位置参数
*   **强制新选项**: `--conn` 和 `--table` 都是必需的选项
*   **简化逻辑**: 不再需要参数验证和向后兼容性处理
*   **清晰语义**: 新接口更加明确和直观

---

## 3. `schema` 命令多表支持方案 🔄 待实现

*   **目标**: 使 `schema` 命令能够通过单个规则文件，验证一个数据源中的多个表。
*   **影响模块**: `cli/commands/schema.py`。
*   **状态**: 🔄 待实现 - 当前只支持单表验证，需要扩展为多表支持

### 3.1. CLI 接口变更

*   **命令格式**: `vlite-cli schema --conn <connection_string> --rules <multi_table_schema.json>`
*   **说明**: 移除 `<data_source>` 位置参数，引入 `--conn` 选项。**需要移除 `--table` 选项**，因为所有目标表将在规则文件中定义。
*   **当前状态**: ❌ 仍需要 `--table` 参数，接口未完全更新

### 3.2. `--rules` 文件格式演进

*   **新格式**: 采用以**表名为键**的顶层JSON对象，其值是原先为单表设计的schema定义。
*   **示例 `multi_table_schema.json`**:
    ```json
    {
      "users": {
        "rules": [
          { "field": "id", "type": "integer", "required": true },
          { "field": "email", "type": "string" }
        ],
        "strict_mode": true
      },
      "products": {
        "rules": [
          { "field": "product_id", "type": "integer" },
          { "field": "price", "type": "float" }
        ]
      }
    }
    ```
*   **当前状态**: ❌ 代码中明确拒绝多表格式，需要移除限制并实现解析逻辑

### 3.3. CLI 分解逻辑变更 (核心设计)

`schema` 命令的CLI层将增加一个**外层循环**来遍历多表规则文件，而内层的分解逻辑完全复用 `Design_Schema_Validation_Command.md` 中已定义的单表分解逻辑。

**当前状态**: ❌ 只有单表分解逻辑 `_decompose_to_atomic_rules`，需要扩展为多表支持

*   **伪代码设计**:

    ```python
    # 位于 cli/commands/schema.py

    def handle_schema_command(conn_str: str, rules_path: Path):
        """处理schema命令的执行"""

        multi_table_schema = load_json(rules_path)
        all_atomic_rules = []
        database = parse_database_from_conn(conn_str)

        # 1. **新增核心逻辑**: 遍历在 --rules 文件中定义的所有表
        for table_name, single_table_schema in multi_table_schema.items():
            
            # 2. **复用现有设计**: 对每个表，调用已有的单表分解逻辑
            #    该逻辑遵循 Design_Schema_Validation_Command.md 中的定义，
            #    将单个表的schema分解为一系列原子的 NotNullRule, RangeRule, EnumRule等。
            #    我们在这里封装一个辅助函数来体现。
            atomic_rules_for_table = decompose_single_table_schema(
                database=database,
                table_name=table_name,
                table_schema_def=single_table_schema
            )
            all_atomic_rules.extend(atomic_rules_for_table)

        # 3. 调用Core Engine，传入包含所有表的所有原子规则的列表
        results = core_engine.execute(all_atomic_rules, connection_string=conn_str)

        # 4. 聚合与渲染结果，按表进行分组
        render_multi_table_results(results)


    def decompose_single_table_schema(database, table_name, table_schema_def) -> list:
        """
        此辅助函数的逻辑严格遵循 Design_Schema_Validation_Command.md。
        它将单表的schema定义分解为原子规则列表。
        """
        decomposed_rules = []
        rules_list = table_schema_def.get("rules", [])

        for field_def in rules_list:
            # 创建 RuleTarget
            target = RuleTarget(database=database, table=table_name, column=field_def["field"])

            # a. 分解出 NotNullRule
            if field_def.get("required"): 
                decomposed_rules.append(NotNullRule(target=target))

            # b. 分解出 EnumRule
            if "enum" in field_def:
                decomposed_rules.append(EnumRule(target=target, params={"allowed_values": field_def["enum"]}))
            
            # c. ... 其他类型的规则分解 (Range, etc.)

        # d. 还可以创建一个整体的、检查所有字段类型和存在性的 table-level SCHEMA 规则
        #    (遵循设计文档中的 SchemaRule 定义)
        # decomposed_rules.append(TableSchemaRule(target=..., params=...))

        return decomposed_rules

    ```

### 3.4. 对Core及Shared模块的影响

*   **无影响**。这是此方案最大的优点。Core层的 `Rule` 接口、各种原子规则的实现、以及 `core_engine` 的执行逻辑完全不需要改变。`RuleTarget` 对象中已经包含了表名，因此Core天生就能处理来自不同表的规则。所有变更都被优雅地限制在了CLI层。
*   **状态**: ✅ 确认无影响 - Core层架构设计良好，支持多表规则

### 3.5. 文件型数据源的多表支持方案 (新增)

*   **背景**: 在测试多表schema验证功能时，CSV等文件格式本质上只包含一个数据集，难以模拟多表场景。
*   **解决方案**: 增强 `SourceParser` 的能力，使其能够将**单个Excel文件作为多表数据源**进行处理。
    *   当 `--conn` 参数指向一个Excel文件 (`.xlsx`, `.xls`) 时，程序会读取该文件的所有工作表 (sheets)。
    *   每一个**工作表 (sheet) 都被视为一个独立的表**。
    *   工作表的**名称 (sheet name) 将被用作表名 (`table_name`)**。
*   **执行流程示例**:
    1.  用户提供 `--conn data.xlsx` 和 `--rules rules.json`。
    2.  `SourceParser` 解析 `data.xlsx`，发现其中包含名为 `users` 和 `products` 的两个sheet。
    3.  `schema` 命令的分解逻辑读取 `rules.json`，发现其中也定义了 `users` 和 `products` 两个表的规则。
    4.  命令开始执行，它会用 `users` 表的规则去验证 `data.xlsx` 中 `users` sheet的数据，用 `products` 表的规则去验证 `products` sheet的数据。
*   **影响模块**: `cli/core/source_parser.py` (或处理数据源解析的相关模块)。

---

## 4. 测试策略

### 4.1. 新接口测试 ✅ 已完成
*   测试 `--conn` 和 `--table` 选项正常工作
*   测试参数验证逻辑
*   测试必需参数缺失时的错误处理
*   **状态**: ✅ 已完成 - check命令的新接口测试已覆盖

### 4.2. 功能测试 🔄 部分完成
*   确保所有现有功能在新接口下正常工作
*   测试文件路径、数据库连接等不同数据源
*   测试内联规则和规则文件
*   **状态**: 🔄 部分完成 - check命令已测试，schema命令的多表功能待测试

### 4.3. 现有测试更新 🔄 部分完成
*   更新所有现有测试以使用新接口
*   保持测试覆盖率在80%以上
*   移除对旧接口的测试
*   **状态**: 🔄 部分完成 - check命令测试已更新，schema命令测试待创建

---

## 5. 总结

该方案通过在CLI层进行接口重构，实现了对多表验证的支持，同时保持了核心引擎的稳定。这充分利用了现有设计的扩展性，是一个低风险、高收益的演进路径。

**当前进展**:
- ✅ **check命令重构**: 已完成，新接口正常工作
- 🔄 **schema命令多表支持**: 待实现，需要扩展接口和解析逻辑
- ✅ **Core层架构**: 确认无影响，设计良好

**关键优势**:
1. **清晰接口**: 新的 `--conn` 和 `--table` 选项语义更加明确
2. **简化逻辑**: 移除了复杂的向后兼容性处理
3. **架构稳定**: Core层完全不受影响
4. **易于维护**: 代码结构更加清晰，易于理解和维护

**下一步工作**:
1. 实现schema命令的多表支持
2. 移除 `--table` 选项要求
3. 支持多表规则文件格式
4. 添加相应的测试覆盖

---

## 6. 详细实施计划

### 6.1. Schema命令多表支持实现步骤

#### 步骤1: 更新CLI接口
- [ ] 移除 `--table` 选项参数
- [ ] 更新函数签名，移除 `table_name` 参数
- [ ] 更新帮助文档和示例

#### 步骤2: 实现多表规则文件解析
- [ ] 移除对 `"tables"` 字段的拒绝逻辑
- [ ] 实现多表JSON格式的解析
- [ ] 验证每个表的规则结构

#### 步骤3: 扩展规则分解逻辑
- [ ] 创建 `_decompose_multi_table_schema` 函数
- [ ] 实现外层循环遍历所有表
- [ ] 复用现有的单表分解逻辑
- [ ] 为每个表设置正确的 `RuleTarget`

#### 步骤4: 更新结果处理
- [ ] 实现按表分组的结果聚合
- [ ] 更新输出格式以显示多表结果
- [ ] 处理跨表的错误统计

#### 步骤5: 添加测试覆盖
- [ ] 创建 `test_schema_command.py` 测试文件
- [ ] 测试多表规则文件解析
- [ ] 测试多表规则分解
- [ ] 测试多表结果输出
- [ ] 确保测试覆盖率保持在80%以上

### 6.2. 风险评估与缓解

**风险**: 多表支持可能影响现有单表功能
**缓解**: 保持向后兼容，单表规则文件仍然有效

**风险**: 性能可能下降（多表验证）
**缓解**: 利用Core层的异步执行能力，并行处理多表

**风险**: 错误处理复杂度增加
**缓解**: 复用现有的错误处理机制，按表分组错误信息
